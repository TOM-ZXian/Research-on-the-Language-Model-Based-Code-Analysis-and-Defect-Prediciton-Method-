# Research-on-the-Language-Model-Based-Code-Analysis-and-Defect-Prediciton-Method-
Research on the Language Model Based Code Analysis and Defect Prediciton Method (Ph.D dissertation by Xian Zhang 2019)

KEYWORDS: software analysis, language model, code naturalness, defect prediction, slice granularity, software measurement, cross-entropy, deep learning

ABSTRACT
With the rapid increase of software size and complexity, software quality problems are becoming more and more serious. Software analysis is an effective method to guarantee software quality and plays an important role in predicting, detecting and confirming software defects. In recent years, code resources have rapidly accumulated and expanded, driving the methods of natural language processing, machine learning and other fields to analyze software. 

Language models are derived from statistical natural language processing. It aims to capture language occurrence rules and usage patterns through corpus, and to estimate the joint probability distribution of language sequences. With this capability, language models can mine software corpus and measure the naturalness of code. Generally, defective codes are more "unnatural". Code naturalness is characterized by the cross-entropy (CE) value measured by language model. The higher the CE value, the lower the probability of occurrence of code and relatively the greater the probability of being defective. In order to improve software quality, some works have been done in recent years to explore defect prediction methods based on code naturalness, but they still have the following shortcomings: traditional language models used have inherent data sparsity, curse of dimensionality and other issues; traditional language models only analyze code data, and the explicit information related to tasks is not effectively utilized; code-naturalness feature is measured only from a single perspective and owns limited discrimination; common coarse-grained defect prediction is difficult to assist in defect finding and location.

Aiming at the above problems, this paper first studies language models based on deep learning technology for software code, then studies code naturalness measurement and defect prediction methods based on such models. The main work includes:

Firstly, an additional information-guided neural language model for software code (NLMCode-AInfo) is proposed. Using the advantages of deep learning methods in pattern learning, a neural language model (NLMCode) based on word-embedding technology and stacked long and short-term memory network is constructed, which overcomes the curse of dimensionality and other issues of traditional language model. On this basis, aiming at the insufficient utilization of non-code information in existing models, an improved language model NLMCode-AInfo is designed to enhance model learning and decision-making ability by introducing task-related explicit information. In code suggestion task, the model integrates the project information represented in word-embedding form into the neural network, which improves the pertinence of data learning and word prediction ability. In the validation experiment on a real corpus with 2.03M lines of code, the improved model's suggestion accuracy rate (MRR index) is 3.6%~24.7% higher than the comparied methods. 

Secondly, a neural language model based code measurement and defect predictor method (NLMDePor) is proposed. This method uses the neural language model NLMCode to automatically calculate the CE values of given software modules, and then combines the generated code-naturalness CE as a new class of metrics with traditional software metrics together to complete more accurate defect prediction. The new metrics introduced by NLMDePor include CE-token obtained by the language model for the code token sequences and CE-AST obtained from the abstract syntax tree node sequences, which characterize codeâ€™s naturalness from different perspectives. To verify the effectiveness of the method, 12 benchmark defect datasets and 20 widely used code metrics were selected. The experimental results show that the discriminantive power of the two CE metrics generated by NLMDePor is better than nearly 50% of the traditional metrics, and they can bring 8.43%~9.58% relative increase in F1-score performance of the prediction models based on the traditional metrics. This shows that the CE metrics are complementary to the traditional metrics.

Thirdly, a bidirectional weighted neural language model based code measurement and defect predictor method (Bi-W-NLMDePor) is proposed. This method first constructs a bidirectional weighted language model for the problems that existing models only measure code in the forward direction and fail to utilize defect information. Based on the built NLMCode-AInfo, this imporved model uses software quality-type information to weigh samples, which enhances/inhibites the learning strength of the model on the clean/defective code, and improves the defect discrimination of CE-type metrics. On the other hand, it also realizes the bidirectional learning of input sequences, where the two improved metrics (M-CE and M-CE-Inv) acquired by the model can more comprehensively characterize the naturalness of code. Based on this model, Bi-W-NLMDePor method shares the label information of training samples in the defect-prediction phase to the language-model-learning phase, overcomes the shortcomings of the original method in isolated processing, and then combines the naturalness features meaursed by the language model with traditional software metrics together to feed prediction models, which improves the defect prediction performance.

Fourthly, software metric design and application of defect prediction methods are implemented on the statement-oriented slice-level granularity. The software module in such prediction granularity is composed of one or more statement-oriented program slices, in which slicing criteria are designed according to specific defect types, such as vulnerability-sensitive function calls. Four metrics are designed for the slice-level defect prediction, including code naturalness features (M-CE and M-CE-Inv) and code size features (lines of code and code token size). Using Bi-W-NLMDePor method, defect prediction applications and method validation are carried out on the slice-level datasets with two types of defect (buffer error and resource management error). The experimental results show that the Bi-W-NLMDePor method can effectively identify these two types of defects, with the F1-socre 9.7%~46.6% higher than the traditional defect prediction methods, 39.5%~66.6% higher than the pattern-based defect detection methods, and 52.5%~61.1% higher than the advanced code similarity-based defect detection methods. According to statistics, the average code lines of the slice-level modules used is 9.16 (far less than the commonly used file-level modules), which effectively compensates for the difficulty of locating buggy code areas and the high cost of code review in coarse-grained defect prediction.

KEYWORDS: software analysis, language model, code naturalness, defect prediction, slice granularity, software measurement, cross-entropy, deep learning
